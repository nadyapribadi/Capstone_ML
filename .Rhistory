repeats = 3) # repetisi
model_6 <- train(coverage ~ src_area,
data = down_train,
method = "rf", # random forest
trControl = ctrl)
saveRDS(model_6, "model_6.RDS") # simpan model
# read model
model_6 <- readRDS("model_6.RDS")
model_6
library(randomForest)
model_6$finalModel
#accuracy model
100 - 23.83
down_validate_pred_cov <- predict(model_6, down_validate, type = "raw")
cm_fb_down <- confusionMatrix(data = down_validate_pred_cov,
reference = down_validate$coverage)
cm_fb_down$table
varImp(model_6)
plot(varImp(model_6))
read_csv("data/comparison.csv")
scotty_test_prep <- down_train %>%
mutate(datetime = start_time) %>%
select(src_area, datetime, coverage)
scotty_test_prep
scotty_test %>%
group_by(src_area) %>%
pad()
scotty_test$coverage <- predict(object = model_4_tuned,
newdata = scotty_test %>%
select(-coverage),
type = "response")
scotty_test
down_train <- down_train %>%
rename(datetime = start_time) %>%
select(-c(nodrivers,prob_area,predicts_area)) %>%
select(src_area, datetime, coverage)
down_train
confusionMatrix(table(data = scotty_test,
reference = down_train))
scotty_test
confusionMatrix(table(data = scotty_test,
reference = down_train$coverage))
confusionMatrix(table(data = scotty_test$coverage,
reference = down_train$coverage))
confusionMatrix(scotty_test$coverage,
down_train$coverage))
confusionMatrix(scotty_test$coverage,
down_train$coverage)
prop.table(table(scotty_test$coverage))
prop.table(table(down_train$coverage))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
scotty_train <- read_csv("data/data-train.csv")
glimpse(scotty_train)
scotty_train[,c("src_area", "src_sub_area", "dest_area", "dest_sub_area", "status")] <- lapply(scotty_train[,c("src_area", "src_sub_area","dest_area","dest_sub_area","status")], as.factor)
scotty_train <- rename(scotty_train, datetime = start_time)
scotty_test <- read_csv("data/data-test.csv")
scotty_test$coverage <- as.factor(scotty_test$coverage)
scotty_test
scotty_train$datetime <- floor_date(scotty_train$datetime, "hour")
scotty_train
scotty_train <- scotty_train %>%
group_by(datetime, src_area, status) %>%
summarise(n = n()) %>%
ungroup()
scotty_train
scotty_train %>%
is.na() %>%
colSums()
summary(scotty_train)
start <- ymd_hms("2017-10-01 00:00:00")
end <- ymd_hms("2017-12-02 23:00:00 ")
time.interval <- start %--% end
time.duration <- as.duration(time.interval)
time.duration / dhours(1)
library(padr)
scotty_train <- scotty_train %>%
group_by(src_area,status) %>%
pad()
scotty_train
scotty_train %>%
is.na() %>%
colSums()
# mengisi NA dgn 0
scotty_train <- scotty_train %>%
mutate(n = replace_na(n, replace = 0))
scotty_train
long_scotty_train <- scotty_train %>%
spread(status, n) %>%
mutate(nodrivers = replace_na(nodrivers, replace = 0)) %>%
mutate(coverage = if_else(nodrivers == 0, "1", "0")) %>%
mutate(coverage = as.factor(coverage))
long_scotty_train
colSums(is.na(long_scotty_train))
prop.table(table(scotty_train$status))
prop.table(table(long_scotty_train$src_area))
pairs(long_scotty_train[,1:5])
long_scotty_train$wdays <- weekdays(long_scotty_train$datetime)
long_scotty_train <- long_scotty_train %>%
mutate(wdays = as.factor(wdays))
hm_matrix <- long_scotty_train %>%
select(src_area, wdays, coverage) %>%
group_by(src_area)
hm_matrix <- data.matrix(hm_matrix)
heatmap(x = hm_matrix, scale="column")
RNGkind(sample.kind = "Rounding")
set.seed(417)
index <- sample(x = nrow(long_scotty_train), size = 0.8*nrow(long_scotty_train))
data_train <- long_scotty_train[index,]
data_validate <- long_scotty_train[-index, ]
prop.table(table(data_train$src_area))
data_train <- data_train[,-3]
data_train
library(caret)
set.seed(417)
up_train <- upSample(x = data_train[, -ncol(data_train)],
y = data_train$src_area)
table(up_train$src_area)
set.seed(417)
up_validate <- upSample(x = data_validate[, -ncol(data_validate)],
y = data_validate$src_area)
table(up_validate$src_area)
set.seed(417)
down_train <- downSample(x = data_train[, -ncol(data_train)],
y = data_train$src_area)
table(down_train$src_area)
set.seed(417)
down_validate <- downSample(x = data_validate[, -ncol(data_validate)],
y = data_validate$src_area)
table(down_validate$src_area)
summary(up_train)
model_1 <- glm(formula = coverage ~ src_area, family = "binomial", data = up_train)
summary(model_1)
library(gtools)
# odds per area ketika sufficient
# --> rasio antara peluang kejadian A dengan peluang kejadian bukan A
exp(model_1$coefficients[[2]])
exp(model_1$coefficients[[3]])
# peluang --> transform log of odds to probability
inv.logit(model_1$coefficients[[2]])
inv.logit(model_1$coefficients[[3]])
up_train$prob_area <- predict(model_1, up_train,  type = "response")
up_train$predicts_area <- as.factor(ifelse(up_train$prob_area > 0.5,
"0","1"))
up_validate$prob_area <- predict(model_1, up_validate,  type = "response")
up_validate$predicts_area <- as.factor(ifelse(up_validate$prob_area > 0.5,
"0","1"))
confusionMatrix(as.factor(up_validate$predicts_area),
up_validate$coverage,
positive = "1")
summary(down_train)
model_2 <- glm(formula = coverage ~ src_area, family = "binomial", data = down_train)
summary(model_2)
library(gtools)
# odds per area ketika sufficient
# --> rasio antara peluang kejadian A dengan peluang kejadian bukan A
exp(model_2$coefficients[[2]])
exp(model_2$coefficients[[3]])
# peluang --> transform log of odds to probability
inv.logit(model_2$coefficients[[2]])
inv.logit(model_2$coefficients[[3]])
down_train$prob_area <- predict(model_2, down_train,  type = "response")
down_train$predicts_area <- as.factor(ifelse(down_train$prob_area > 0.5,
"0","1"))
down_validate$prob_area <- predict(model_2, down_validate,  type = "response")
down_validate$predicts_area <- as.factor(ifelse(down_validate$prob_area > 0.5,
"0","1"))
confusionMatrix(as.factor(down_validate$predicts_area),
down_validate$coverage,
positive = "1")
library(partykit)
model_3 <- ctree(formula = coverage ~ src_area,
data = up_train)
plot(model_3, type = "simple")
model_3
# prediksi kelas di data test
pred_up_validate <- predict(object = model_3,
newdata = up_validate,
type = "response")
# confusion matrix data test
confusionMatrix(data = pred_up_validate,
reference = up_validate$coverage,
positive = "1")
# prediksi kelas di data train
pred_up_train <- predict(object = model_3,
newdata = up_train,
type = "response")
# confusion matrix data train
confusionMatrix(data = pred_up_train,
reference = up_train$coverage,
positive = "1")
model_3_tuned <- ctree(formula = coverage ~ src_area,
data = up_train,
control = ctree_control(mincriterion = 0,
minsplit = 50,
minbucket = 15))
plot(model_3_tuned, type = "simple")
# prediksi kelas di data test
pred_up_validate_tuned <- predict(object = model_3_tuned,
newdata = up_validate,
type = "response")
# confusion matrix data test
confusionMatrix(data = pred_up_validate_tuned,
reference = up_validate$coverage,
positive = "1")
# prediksi kelas di data train
pred_up_train_tuned <- predict(object = model_3_tuned,
newdata = up_train,
type = "response")
# confusion matrix data train
confusionMatrix(data = pred_up_train_tuned,
reference = up_train$coverage,
positive = "1")
library(partykit)
model_4 <- ctree(formula = coverage ~ src_area,
data = down_train)
plot(model_4, type = "simple")
model_4
# prediksi kelas di data test
pred_down_validate <- predict(object = model_4,
newdata = down_validate,
type = "response")
# confusion matrix data test
confusionMatrix(data = pred_down_validate,
reference = down_validate$coverage,
positive = "1")
# prediksi kelas di data train
pred_down_train <- predict(object = model_4,
newdata = down_train,
type = "response")
# confusion matrix data train
confusionMatrix(data = pred_down_train,
reference = down_train$coverage,
positive = "1")
model_4_tuned <- ctree(formula = coverage ~ src_area,
data = down_train,
control = ctree_control(mincriterion = 0,
minsplit = 50,
minbucket = 15))
plot(model_4_tuned, type = "simple")
# prediksi kelas di data test
pred_down_validate_tuned <- predict(object = model_4_tuned,
newdata = down_validate,
type = "response")
# confusion matrix data test
confusionMatrix(data = pred_down_validate_tuned,
reference = down_validate$coverage,
positive = "1")
# prediksi kelas di data train
pred_down_train_tuned <- predict(object = model_4_tuned,
newdata = down_train,
type = "response")
# confusion matrix data train
confusionMatrix(data = pred_down_train_tuned,
reference = down_train$coverage,
positive = "1")
set.seed(417)
ctrl <- trainControl(method = "repeatedcv",
number = 5, # k-fold
repeats = 3) # repetisi
model_5 <- train(coverage ~ src_area,
data = up_train,
method = "rf", # random forest
trControl = ctrl)
saveRDS(model_5, "model_5.RDS") # simpan model
# read model
model_5 <- readRDS("model_5.RDS")
model_5
library(randomForest)
model_5$finalModel
#accuracy model
100 - 23.86
up_validate_pred_cov <- predict(model_5, up_validate, type = "raw")
cm_fb_up <- confusionMatrix(data = up_validate_pred_cov,
reference = up_validate$coverage)
cm_fb_up$table
varImp(model_5)
plot(varImp(model_5))
set.seed(417)
ctrl <- trainControl(method = "repeatedcv",
number = 5, # k-fold
repeats = 3) # repetisi
model_6 <- train(coverage ~ src_area,
data = down_train,
method = "rf", # random forest
trControl = ctrl)
saveRDS(model_6, "model_6.RDS") # simpan model
# read model
model_6 <- readRDS("model_6.RDS")
model_6
library(randomForest)
model_6$finalModel
#accuracy model
100 - 23.83
down_validate_pred_cov <- predict(model_6, down_validate, type = "raw")
cm_fb_down <- confusionMatrix(data = down_validate_pred_cov,
reference = down_validate$coverage)
cm_fb_down$table
varImp(model_6)
plot(varImp(model_6))
read_csv("data/comparison.csv")
scotty_test_prep <- down_train %>%
mutate(datetime = datetime) %>%
select(src_area, datetime, coverage)
scotty_test_prep
scotty_test %>%
group_by(src_area) %>%
pad()
scotty_test$coverage <- predict(object = model_4_tuned,
newdata = scotty_test %>%
select(-coverage),
type = "response")
scotty_test
# Predict the target using your model
pred_test <- predict(object = model_4_tuned,
newdata = scotty_test %>%
select(-coverage),
type = "response")
# Create submission data
submission <- scotty_test %>%
mutate(coverage = pred_test)
# save data
write.csv(submission, "submission-nadya.csv", row.names = F)
# check first 3 data
head(submission, 3)
library(tidymodels)
library(lime)
library(rmarkdown)
# Prepare the reverse recipes
rec_rev <- function(x){
y <- x %>% select_if(is.numeric)
for (i in 1:length(names(y))) {
y[ , i] <- y[ ,i] * rec$steps[[3]]$sds[names(y)[i]]
}
x <- x %>% select_if(is.factor) %>% bind_cols(y)
return(x)
}
down_train
rec <- recipe(src_area ~ coverage, data = training(down_train)) %>%
step_downsample(coverage) %>%
step_scale(all_numeric()) %>%
step_nzv(all_numeric()) %>%
prep()
rec <- recipe(src_area ~ coverage, data = training(down_train)) %>%
step_downsample(coverage)
rec <- recipe(src_area ~ coverage, data = training(down_train))
library(recipes)
library(recipes)
rec <- recipe(src_area ~ coverage, data = training(down_train)) %>%
step_downsample(coverage) %>%
step_scale(all_numeric()) %>%
step_nzv(all_numeric()) %>%
prep()
#define model spec
model_spec <- rand_forest(
mode = "classification",
mtry = 2,
trees = 500,
min_n = 1)
#define model engine
model_spec <- set_engine(model_spec,
engine = "ranger",
seed = 123,
num.threads = parallel::detectCores(),
importance = "impurity")
#model fitting
set.seed(123)
model <- fit_xy(
object = model_spec,
x = select(down_train, -coverage),
y = select(down_train, coverage)
#define model spec
model_spec <- rand_forest(
mode = "classification",
mtry = 2,
trees = 500,
min_n = 1)
#define model engine
model_spec <- set_engine(model_spec,
engine = "ranger",
seed = 123,
num.threads = parallel::detectCores(),
importance = "impurity")
#model fitting
set.seed(123)
model <- fit_xy(
object = model_spec,
x = select(down_train, -coverage),
y = select(down_train, coverage))
install.packages("ranger")
#define model spec
model_spec <- rand_forest(
mode = "classification",
mtry = 2,
trees = 500,
min_n = 1)
#define model engine
model_spec <- set_engine(model_spec,
engine = "ranger",
seed = 123,
num.threads = parallel::detectCores(),
importance = "impurity")
#model fitting
set.seed(123)
model <- fit_xy(
object = model_spec,
x = select(down_train, -coverage),
y = select(down_train, coverage))
lime_test <- predict(model5, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$coverage)
lime_test <- predict(model_5, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$coverage)
lime_test <- predict(model_6, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$coverage)
lime_test <- predict(model_6, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$coverage)
predict(model_6, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$coverage)
lime_test <- predict(model_6, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$coverage,
type = "response")
lime_test <- predict(model_6, new_data = scotty_test %>% select(-coverage)))
lime_test <- predict(model_6, new_data = scotty_test %>% select(-coverage))
lime_test %>%
summarise(accuracy = accuracy_vec(true, .pred_class),
sensitivity = sens_vec(true, .pred_class),
precision = precision_vec(true, .pred_class),
specificity = spec_vec(true, .pred_class))
predict(model_6, new_data = scotty_test %>% select(-coverage))
predict(model_6, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$coverage
predict(model_6, new_data = scotty_test %>% select(-coverage)) %>%
lime_test <- predict(model_6, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$coverage))
lime_test <- predict(model_6, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$coverage)
predict(model_6, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$coverage)
predict(model_6, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$coverage
predict(model_6, new_data = scotty_test %>% select(-coverage)) %>%
predict(model_6, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$coverage
predict(model_6, new_data = scotty_test %>% select(-coverage)) %>%
predict(model_6, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$coverage)
predict(model_6, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$coverage)
predict(model_6, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$coverage)
predict(model_6, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$coverage)
predict(model_6, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$coverage)
predict(model_6, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$coverage)
predict(model_6, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$coverage)
predict(model_6, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$coverage)
predict(model_6, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$coverage)
predict(model_6, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$coverage)
lime_test <- predict(model_6, new_data = scotty_test %>% select(-coverage))
lime_test <- predict(model_6, new_data = scotty_test %>% select(-coverage), type = "raw")
lime_pred <- predict(model_6, new_data = scotty_test %>% select(-coverage), type = "raw")
confusionMatrix(data = lime_pred,
reference = scotty_test$coverage)
lime_pred <- predict(model_spec, new_data = scotty_test %>% select(-coverage), type = "raw")
# Predict the target using your model
scotty_test$coverage <- predict(object = model_4_tuned,
newdata = scotty_test %>%
select(-coverage),
type = "response")
scotty_test$coverage <- as.factor(ifelse(scotty_test$coverage == 0,
"insufficient","sufficient"))
# Create submission data
submission <- scotty_test
# save data
write.csv(submission, "submission-nadya.csv", row.names = F)
# check first 3 data
head(submission, 3)
library(tidymodels)
library(lime)
library(rmarkdown)
#define model spec
model_spec <- rand_forest(
mode = "classification",
mtry = 2,
trees = 500,
min_n = 1)
#define model engine
model_spec <- set_engine(model_spec,
engine = "ranger",
seed = 123,
num.threads = parallel::detectCores(),
importance = "impurity")
#model fitting
set.seed(123)
model <- fit_xy(
object = model_spec,
x = select(down_train, -coverage),
y = select(down_train, coverage))
lime_pred <- predict(model_spec, new_data = scotty_test %>% select(-coverage), type = "response")
pred_test_lime <- predict(model, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$coverage)
lime_pred <- predict(model, new_data = scotty_test %>% select(-coverage), type = "response")
lime_pred <- predict(model, new_data = scotty_test %>% select(-coverage), type = "raw")
pred_test_lime <- predict(model, new_data = scotty_test %>% select(-coverage)) %>%
bind_cols(true = scotty_test$src_area)
